#!/usr/bin/env python3
"""
VÃ‰RIFICATION DATA LEAKAGE
DÃ©tecte les features suspectes qui pourraient causer la performance parfaite
"""

import pandas as pd
import numpy as np
from sklearn.feature_selection import mutual_info_classif
from sklearn.preprocessing import StandardScaler

def analyze_features():
    """Analyse les features pour dÃ©tecter le data leakage"""
    print("ğŸ” VÃ‰RIFICATION DATA LEAKAGE")
    print("=" * 50)
    
    df = pd.read_csv("../data_prepared_COMPLET.csv")
    
    # Target
    target_col = 'entree_pmr'
    y = df[target_col]
    
    # Features numÃ©riques
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if target_col in numeric_cols:
        numeric_cols.remove(target_col)
    
    X = df[numeric_cols]
    
    print(f"ğŸ“Š Features analysÃ©es: {len(numeric_cols)}")
    print(f"ğŸ“Š Target: {target_col}")
    
    # 1. CorrÃ©lations avec la target
    print(f"\nğŸ”— CORRÃ‰LATIONS AVEC LA TARGET:")
    print("-" * 40)
    
    correlations = []
    for col in numeric_cols:
        corr = df[col].corr(y)
        correlations.append((col, abs(corr)))
    
    # Tri par corrÃ©lation dÃ©croissante
    correlations.sort(key=lambda x: x[1], reverse=True)
    
    print("Top 10 corrÃ©lations les plus fortes:")
    for i, (col, corr) in enumerate(correlations[:10], 1):
        status = "ğŸš¨" if corr > 0.9 else "âš ï¸" if corr > 0.7 else "âœ…"
        print(f"{i:2d}. {col:<30} {corr:.4f} {status}")
    
    # 2. Information mutuelle
    print(f"\nğŸ§  INFORMATION MUTUELLE:")
    print("-" * 40)
    
    # Normalisation pour l'information mutuelle
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Calcul information mutuelle
    mi_scores = mutual_info_classif(X_scaled, y, random_state=42)
    
    # Tri par information mutuelle
    mi_results = list(zip(numeric_cols, mi_scores))
    mi_results.sort(key=lambda x: x[1], reverse=True)
    
    print("Top 10 features les plus informatives:")
    for i, (col, score) in enumerate(mi_results[:10], 1):
        status = "ğŸš¨" if score > 1.5 else "âš ï¸" if score > 1.0 else "âœ…"
        print(f"{i:2d}. {col:<30} {score:.4f} {status}")
    
    # 3. Features parfaitement corrÃ©lÃ©es (suspects)
    print(f"\nğŸš¨ FEATURES SUSPECTES (corrÃ©lation > 90%):")
    print("-" * 50)
    
    suspects = [col for col, corr in correlations if corr > 0.9]
    
    if suspects:
        print("âš ï¸  Features avec corrÃ©lation > 90% (possibles fuites):")
        for col in suspects:
            corr = df[col].corr(y)
            print(f"   â€¢ {col}: {corr:.4f}")
            
            # Analyse des valeurs
            unique_vals = df[col].nunique()
            print(f"     â†’ Valeurs uniques: {unique_vals}")
            
            if unique_vals <= 10:
                print(f"     â†’ Distribution: {dict(df[col].value_counts().head())}")
    else:
        print("âœ… Aucune feature avec corrÃ©lation > 90%")
    
    # 4. Analyse des noms de colonnes
    print(f"\nğŸ·ï¸  ANALYSE DES NOMS DE FEATURES:")
    print("-" * 40)
    
    suspicious_keywords = ['id', 'key', 'index', 'target', 'label', 'result', 'outcome']
    
    suspicious_cols = []
    for col in numeric_cols:
        col_lower = col.lower()
        for keyword in suspicious_keywords:
            if keyword in col_lower:
                suspicious_cols.append((col, keyword))
    
    if suspicious_cols:
        print("âš ï¸  Noms de colonnes suspects:")
        for col, keyword in suspicious_cols:
            print(f"   â€¢ {col} (contient '{keyword}')")
    else:
        print("âœ… Noms de colonnes normaux")
    
    return correlations, mi_results, suspects

def main():
    """Fonction principale"""
    print("ğŸ•µï¸â€â™‚ï¸ DÃ‰TECTION DATA LEAKAGE - DEEP LEARNING")
    print("=" * 60)
    
    try:
        correlations, mi_results, suspects = analyze_features()
        
        print(f"\nğŸ“‹ RÃ‰SUMÃ‰:")
        print("-" * 20)
        
        if suspects:
            print(f"ğŸš¨ {len(suspects)} feature(s) suspecte(s) dÃ©tectÃ©e(s)")
            print("   â†’ CorrÃ©lation > 90% avec la target")
            print("   â†’ Possible data leakage !")
            print("\nğŸ’¡ RECOMMANDATIONS:")
            print("   1. VÃ©rifier l'origine de ces features")
            print("   2. S'assurer qu'elles sont disponibles AVANT la prÃ©diction")
            print("   3. Les exclure si elles contiennent l'info future")
        else:
            print("âœ… Pas de data leakage Ã©vident dÃ©tectÃ©")
            print("   â†’ Performance Ã©levÃ©e peut Ãªtre lÃ©gitime")
            print("   â†’ Dataset de qualitÃ© avec features pertinentes")
        
        print(f"\nğŸ¯ CONCLUSION:")
        if len(suspects) > 0:
            print("   Performance parfaite = Data leakage probable")
        else:
            print("   Performance parfaite = Dataset de trÃ¨s haute qualitÃ©")
            print("   â†’ FÃ©licitations pour le preprocessing ! ğŸ‰")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")

if __name__ == "__main__":
    main()
