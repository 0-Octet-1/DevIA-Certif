#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de test et optimisation des seuils de dÃ©cision
Projet: PrÃ©diction accessibilitÃ© PMR
Auteur: Certification RNCP 38616
"""

import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import warnings
import os
warnings.filterwarnings('ignore')

# Configuration
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def charger_modele_et_donnees():
    """Charge le modÃ¨le et les donnÃ©es de test"""
    print("ğŸ”„ Chargement du modÃ¨le et des donnÃ©es...")
    
    # Charger le modÃ¨le
    with open('../3-TravailModelisÃ©/Model_bloc3.pkl', 'rb') as f:
        model_data = pickle.load(f)
    
    model = model_data['model']
    features_list = model_data['features']
    
    # Charger les donnÃ©es prÃ©parÃ©es
    file_path = os.path.join('..', '2-TravailPreparationdesDonnÃ©es', 'data_prepared_EXPLORATION.csv')
    df = pd.read_csv(file_path)
    
    print(f"âœ… ModÃ¨le chargÃ©: {type(model).__name__}")
    print(f"âœ… Dataset: {df.shape[0]:,} lignes, {df.shape[1]} colonnes")
    
    return model, features_list, df

def preparer_donnees_test(df, features_list):
    """PrÃ©pare les donnÃ©es de test avec le mÃªme encodage que l'entraÃ®nement"""
    print("ğŸ”„ PrÃ©paration des donnÃ©es de test...")
    
    # Filtrer les donnÃ©es avec target non-nulle
    df_test = df[df['entree_pmr'].notna()].copy()
    
    # Encoder les variables catÃ©gorielles
    label_encoders = {}
    for col in df_test.columns:
        if df_test[col].dtype == 'object' and col in features_list:
            le = LabelEncoder()
            df_test[col] = le.fit_transform(df_test[col].astype(str))
            label_encoders[col] = le
    
    # SÃ©lectionner les features
    X_test = df_test[features_list]
    y_test = df_test['entree_pmr'].astype(int)
    
    print(f"âœ… DonnÃ©es de test: {X_test.shape[0]:,} Ã©chantillons")
    print(f"âœ… Distribution: {y_test.value_counts().to_dict()}")
    
    return X_test, y_test

def tester_seuils(model, X_test, y_test, seuils=None):
    """Teste diffÃ©rents seuils et calcule les mÃ©triques"""
    if seuils is None:
        seuils = np.arange(0.1, 0.55, 0.05)
    
    print(f"ğŸ”„ Test de {len(seuils)} seuils...")
    
    # PrÃ©dictions probabilistes
    y_proba = model.predict_proba(X_test)[:, 1]
    
    resultats = []
    
    for seuil in seuils:
        # PrÃ©dictions avec seuil personnalisÃ©
        y_pred = (y_proba >= seuil).astype(int)
        
        # Calcul des mÃ©triques
        f1 = f1_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        
        # Matrice de confusion
        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
        
        resultats.append({
            'seuil': seuil,
            'f1_score': f1,
            'precision': precision,
            'recall': recall,
            'tp': tp,
            'tn': tn,
            'fp': fp,
            'fn': fn
        })
        
        print(f"Seuil {seuil:.2f}: F1={f1:.3f}, Precision={precision:.3f}, Recall={recall:.3f}")
    
    return pd.DataFrame(resultats)

def creer_graphique_seuils(resultats_df):
    """CrÃ©e un graphique comparatif des seuils"""
    print("ğŸ“Š CrÃ©ation du graphique comparatif...")
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # F1-Score
    ax1.plot(resultats_df['seuil'], resultats_df['f1_score'], 'o-', linewidth=2, markersize=6)
    ax1.set_title('F1-Score par Seuil', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Seuil de dÃ©cision')
    ax1.set_ylabel('F1-Score')
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(0, 1)
    
    # Meilleur seuil
    best_idx = resultats_df['f1_score'].idxmax()
    best_seuil = resultats_df.loc[best_idx, 'seuil']
    best_f1 = resultats_df.loc[best_idx, 'f1_score']
    ax1.axvline(x=best_seuil, color='red', linestyle='--', alpha=0.7)
    ax1.annotate(f'Optimal: {best_seuil:.2f}\nF1: {best_f1:.3f}', 
                xy=(best_seuil, best_f1), xytext=(best_seuil+0.05, best_f1-0.1),
                arrowprops=dict(arrowstyle='->', color='red'), fontsize=10)
    
    # Precision vs Recall
    ax2.plot(resultats_df['seuil'], resultats_df['precision'], 'o-', label='Precision', linewidth=2)
    ax2.plot(resultats_df['seuil'], resultats_df['recall'], 's-', label='Recall', linewidth=2)
    ax2.set_title('Precision vs Recall par Seuil', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Seuil de dÃ©cision')
    ax2.set_ylabel('Score')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 1)
    
    # Vrais/Faux Positifs
    ax3.plot(resultats_df['seuil'], resultats_df['tp'], 'o-', label='Vrais Positifs', linewidth=2)
    ax3.plot(resultats_df['seuil'], resultats_df['fp'], 's-', label='Faux Positifs', linewidth=2)
    ax3.set_title('Vrais vs Faux Positifs', fontsize=14, fontweight='bold')
    ax3.set_xlabel('Seuil de dÃ©cision')
    ax3.set_ylabel('Nombre')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Vrais/Faux NÃ©gatifs
    ax4.plot(resultats_df['seuil'], resultats_df['tn'], 'o-', label='Vrais NÃ©gatifs', linewidth=2)
    ax4.plot(resultats_df['seuil'], resultats_df['fn'], 's-', label='Faux NÃ©gatifs', linewidth=2)
    ax4.set_title('Vrais vs Faux NÃ©gatifs', fontsize=14, fontweight='bold')
    ax4.set_xlabel('Seuil de dÃ©cision')
    ax4.set_ylabel('Nombre')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Sauvegarder
    filename = 'optimisation_seuils_comparaison.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š Graphique sauvegardÃ©: {filename}")
    
    plt.show()
    
    return best_seuil, best_f1

def tester_etablissements_fictifs(model, features_list, seuils_a_tester):
    """Teste les Ã©tablissements fictifs avec diffÃ©rents seuils"""
    print("ğŸ¢ Test des Ã©tablissements fictifs...")
    
    # Ã‰tablissements de test
    etablissements = [
        {
            'nom': 'Restaurant Parfait',
            'activite': 'Restaurant',
            'entree_largeur_mini': 120,
            'entree_marches': 0,
            'sanitaires_presence': 1,
            'stationnement_pmr': 1,
            'transport_station_presence': 1,
            'attendu': 'ACCESSIBLE'
        },
        {
            'nom': 'CafÃ© ProblÃ©matique',
            'activite': 'Restaurant', 
            'entree_largeur_mini': 75,
            'entree_marches': 3,
            'sanitaires_presence': 0,
            'stationnement_pmr': 0,
            'transport_station_presence': 0,
            'attendu': 'NON ACCESSIBLE'
        },
        {
            'nom': 'Pharmacie Accessible',
            'activite': 'Commerce',
            'entree_largeur_mini': 100,
            'entree_marches': 0,
            'sanitaires_presence': 1,
            'stationnement_pmr': 1,
            'transport_station_presence': 1,
            'attendu': 'ACCESSIBLE'
        }
    ]
    
    # CrÃ©er DataFrame avec toutes les features nÃ©cessaires
    test_data = []
    for etab in etablissements:
        # Initialiser avec des valeurs par dÃ©faut
        row = {feature: 0 for feature in features_list}
        
        # Remplir avec les valeurs spÃ©cifiÃ©es
        for key, value in etab.items():
            if key in features_list:
                if key == 'activite':
                    # Encoder l'activitÃ© (approximation)
                    row[key] = 1 if value == 'Restaurant' else 2
                else:
                    row[key] = value
        
        test_data.append(row)
    
    X_fictif = pd.DataFrame(test_data)
    
    # PrÃ©dictions
    y_proba_fictif = model.predict_proba(X_fictif)[:, 1]
    
    print("\n" + "="*80)
    print("RÃ‰SULTATS SUR Ã‰TABLISSEMENTS FICTIFS")
    print("="*80)
    
    for i, etab in enumerate(etablissements):
        print(f"\nğŸ¢ {etab['nom'].upper()}:")
        print(f"   Largeur: {etab['entree_largeur_mini']}cm, Marches: {etab['entree_marches']}")
        print(f"   Sanitaires: {'Oui' if etab['sanitaires_presence'] else 'Non'}")
        print(f"   ProbabilitÃ© accessible: {y_proba_fictif[i]:.3f}")
        print(f"   Attendu: {etab['attendu']}")
        
        print("   PrÃ©dictions par seuil:")
        for seuil in seuils_a_tester:
            pred = "ACCESSIBLE" if y_proba_fictif[i] >= seuil else "NON ACCESSIBLE"
            correct = "âœ…" if pred == etab['attendu'] else "âŒ"
            print(f"     Seuil {seuil:.2f}: {pred} {correct}")

def main():
    """Fonction principale"""
    print("="*80)
    print("ğŸ¯ OPTIMISATION DES SEUILS DE DÃ‰CISION")
    print("="*80)
    
    try:
        # 1. Charger modÃ¨le et donnÃ©es
        model, features_list, df = charger_modele_et_donnees()
        
        # 2. PrÃ©parer donnÃ©es de test
        X_test, y_test = preparer_donnees_test(df, features_list)
        
        # 3. Tester diffÃ©rents seuils
        seuils = np.arange(0.1, 0.55, 0.05)
        resultats = tester_seuils(model, X_test, y_test, seuils)
        
        # 4. CrÃ©er graphique et identifier le meilleur seuil
        best_seuil, best_f1 = creer_graphique_seuils(resultats)
        
        # 5. Afficher le rÃ©sumÃ©
        print("\n" + "="*80)
        print("ğŸ“Š RÃ‰SUMÃ‰ DE L'OPTIMISATION")
        print("="*80)
        print(f"ğŸ¯ Meilleur seuil: {best_seuil:.2f}")
        print(f"ğŸ¯ Meilleur F1-Score: {best_f1:.3f}")
        
        # Top 3 des seuils
        top3 = resultats.nlargest(3, 'f1_score')
        print(f"\nğŸ† TOP 3 DES SEUILS:")
        for i, row in top3.iterrows():
            print(f"   {row['seuil']:.2f}: F1={row['f1_score']:.3f}, Precision={row['precision']:.3f}, Recall={row['recall']:.3f}")
        
        # 6. Tester sur Ã©tablissements fictifs
        seuils_test = [0.2, best_seuil, 0.3, 0.5]
        tester_etablissements_fictifs(model, features_list, seuils_test)
        
        # 7. Recommandations
        print("\n" + "="*80)
        print("ğŸ’¡ RECOMMANDATIONS")
        print("="*80)
        
        if best_seuil < 0.25:
            print("âš ï¸  Seuil optimal trÃ¨s bas - Risque de faux positifs Ã©levÃ©")
            print("ğŸ’¡ ConsidÃ©rer des rÃ¨gles mÃ©tier complÃ©mentaires")
        elif best_seuil > 0.4:
            print("âš ï¸  Seuil optimal Ã©levÃ© - Risque de manquer des Ã©tablissements accessibles")
            print("ğŸ’¡ VÃ©rifier la qualitÃ© des donnÃ©es d'entraÃ®nement")
        else:
            print("âœ… Seuil optimal dans une plage raisonnable")
        
        print(f"\nğŸ¯ Seuil recommandÃ© pour la production: {best_seuil:.2f}")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
