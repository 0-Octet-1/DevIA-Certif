#!/usr/bin/env python3
"""
Script de test du mod√®le ML - Pr√©diction d'accessibilit√© PMR
Charge le mod√®le sauvegard√© et teste sur des exemples concrets
"""

import pandas as pd
import numpy as np
import joblib
import warnings
import os
warnings.filterwarnings('ignore')

def load_model_and_data():
    """charge le mod√®le et les donn√©es de test"""
    print("chargement du mod√®le sauvegard√©...")
    
    try:
        # charger le mod√®le
        file_path_model = os.path.join('..', '3-TravailModelis√©', 'Model_bloc3.pkl')
        model_data = joblib.load(file_path_model)
        
        # extraire le mod√®le et les features du dictionnaire
        if isinstance(model_data, dict):
            model = model_data['model']
            feature_names = model_data.get('features', [])  # r√©cup√©rer les features sauvegard√©es
            print(f"mod√®le charg√©: {type(model).__name__}")
            print(f"algorithme: {model_data.get('model_name', 'inconnu')}")
            
            # r√©cup√©rer le f1-score depuis performance
            performance = model_data.get('performance', {})
            f1_score = performance.get('f1_score', 'inconnu')
            print(f"f1-score: {f1_score}")
            print(f"features sauvegard√©es: {len(feature_names)} colonnes")
        else:
            model = model_data
            feature_names = []
            print(f"mod√®le charg√©: {type(model).__name__}")
            print("attention: pas de m√©tadonn√©es de features trouv√©es")
        
        # charger les donn√©es pr√©par√©es pour r√©cup√©rer la structure
        file_path = os.path.join('..', '2-TravailPreparationdesDonn√©es', 'data_prepared_EXPLORATION.csv')
        df = pd.read_csv(file_path)
        print(f"donn√©es charg√©es: {len(df)} lignes")
        
        return model, df, feature_names
        
    except Exception as e:
        print(f"erreur chargement: {e}")
        return None, None, []

def prepare_test_sample_simple(df, feature_names):
    """pr√©pare un √©chantillon de test en utilisant les donn√©es d√©j√† pr√©par√©es"""
    
    print("pr√©paration √©chantillon de test...")
    
    # chercher des √©tablissements avec entree_pmr connu pour validation
    df_with_target = df[df['entree_pmr'].notna()].copy()
    
    if len(df_with_target) == 0:
        print("aucun √©tablissement avec v√©rit√© terrain trouv√©")
        sample_indices = np.random.choice(df.index, size=min(4, len(df)), replace=False)
        sample_original = df.loc[sample_indices].copy()
    else:
        # prendre un √©chantillon √©quilibr√©
        accessible = df_with_target[df_with_target['entree_pmr'] == True]
        non_accessible = df_with_target[df_with_target['entree_pmr'] == False]
        
        n_accessible = min(2, len(accessible))
        n_non_accessible = min(2, len(non_accessible))
        
        sample_parts = []
        if n_accessible > 0:
            sample_parts.append(accessible.sample(n=n_accessible, random_state=42))
            print(f"trouv√© {n_accessible} √©tablissements accessibles")
        
        if n_non_accessible > 0:
            sample_parts.append(non_accessible.sample(n=n_non_accessible, random_state=42))
            print(f"trouv√© {n_non_accessible} √©tablissements non accessibles")
        
        if sample_parts:
            sample_original = pd.concat(sample_parts, ignore_index=True)
        else:
            sample_indices = np.random.choice(df.index, size=min(4, len(df)), replace=False)
            sample_original = df.loc[sample_indices].copy()
    
    print(f"√©chantillon final: {len(sample_original)} √©tablissements")
    
    # utiliser exactement les features sauvegard√©es dans le bon ordre
    if feature_names and len(feature_names) > 0:
        print(f"utilisation des {len(feature_names)} features sauvegard√©es")
        
        # v√©rifier que toutes les features sont disponibles
        missing_features = [f for f in feature_names if f not in df.columns]
        if missing_features:
            print(f"erreur: features manquantes: {missing_features}")
            return None, None, None
        
        # utiliser exactement les features dans l'ordre sauvegard√©
        test_samples = sample_original[feature_names].copy()
        
        # ENCODER LES VARIABLES CATEGORIELLES (m√™me logique que 03_model_training.py)
        from sklearn.preprocessing import LabelEncoder
        
        print("encodage des variables cat√©gorielles...")
        for col in test_samples.columns:
            if test_samples[col].dtype == 'object':  # variable cat√©gorielle
                print(f"  encodage colonne: {col}")
                # remplacer les valeurs manquantes
                test_samples[col] = test_samples[col].fillna('Unknown')
                # encoder avec LabelEncoder
                le = LabelEncoder()
                test_samples[col] = le.fit_transform(test_samples[col].astype(str))
        
        # g√©rer les valeurs manquantes num√©riques
        test_samples = test_samples.fillna(0)
        
        # v√©rifier que tout est num√©rique maintenant
        for col in test_samples.columns:
            if test_samples[col].dtype == 'object':
                print(f"attention: colonne {col} encore textuelle")
        
        print(f"donn√©es pr√©par√©es: {test_samples.shape}")
        
    else:
        print("erreur: pas de features sauvegard√©es")
        return None, None, None
    
    return test_samples, feature_names, sample_original

def test_model_predictions(model, test_samples, original_df):
    """teste le mod√®le sur les √©chantillons avec d√©tails complets"""
    print(f"\ntest du mod√®le sur {len(test_samples)} √©chantillons:")
    print("=" * 80)
    
    # pr√©dictions avec seuil optimis√© (correction du biais 94% non accessible)
    probabilities = model.predict_proba(test_samples)
    
    # appliquer le seuil optimal de 0.2 (au lieu de 0.5 par d√©faut)
    # am√©lioration f1-score: 0.208 ‚Üí 0.373 (+79%)
    optimal_threshold = 0.35
    predictions = (probabilities[:, 1] >= optimal_threshold).astype(int)
    
    print(f"üéØ seuil de d√©cision optimis√©: {optimal_threshold} (correction biais)")
    print(f"   am√©lioration f1-score: +79% vs mod√®le standard")
    
    # afficher les r√©sultats d√©taill√©s
    for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
        result = "ACCESSIBLE" if pred == 1 else "NON ACCESSIBLE"
        confidence = prob[pred] * 100
        
        # r√©cup√©rer les infos de l'√©tablissement original
        etablissement = original_df.iloc[i]
        
        print(f"\nüè¢ √âTABLISSEMENT {i+1}:")
        print(f"   Nom: {etablissement.get('name', 'Non renseign√©')}")
        print(f"   Activit√©: {etablissement.get('activite', 'Non renseign√©')}")
        print(f"   Commune: {etablissement.get('commune', 'Non renseign√©')}")
        
        print(f"\nüìä CARACT√âRISTIQUES D'ACCESSIBILIT√â:")
        print(f"   Largeur entr√©e: {etablissement.get('entree_largeur_mini', 'Non renseign√©')} cm")
        print(f"   Nombre de marches: {etablissement.get('entree_marches', 'Non renseign√©')}")
        
        # sanitaires
        sanitaires = etablissement.get('sanitaires_presence')
        sanitaires_txt = 'Oui' if sanitaires == 1 else 'Non' if sanitaires == 0 else 'Non renseign√©'
        print(f"   Sanitaires pr√©sents: {sanitaires_txt}")
        
        # stationnement PMR
        parking = etablissement.get('stationnement_pmr')
        parking_txt = 'Oui' if parking == 1 else 'Non' if parking == 0 else 'Non renseign√©'
        print(f"   Stationnement PMR: {parking_txt}")
        
        # transport
        transport = etablissement.get('transport_station_presence')
        transport_txt = 'Oui' if transport == 1 else 'Non' if transport == 0 else 'Non renseign√©'
        print(f"   Transport accessible: {transport_txt}")
        
        print(f"\nüéØ PR√âDICTION DU MOD√àLE (seuil {optimal_threshold}):")
        print(f"   R√©sultat: {result}")
        print(f"   Probabilit√© accessible: {prob[1]:.3f}")
        print(f"   Seuil standard (0.5): {'ACCESSIBLE' if prob[1] >= 0.5 else 'NON ACCESSIBLE'}")
        print(f"   Seuil optimis√© ({optimal_threshold}): {result}")
        
        # v√©rit√© terrain si disponible
        if 'entree_pmr' in etablissement and pd.notna(etablissement['entree_pmr']):
            vraie_valeur = "ACCESSIBLE" if etablissement['entree_pmr'] else "NON ACCESSIBLE"
            correct = "‚úÖ CORRECT" if (etablissement['entree_pmr'] and pred == 1) or (not etablissement['entree_pmr'] and pred == 0) else "‚ùå INCORRECT"
            print(f"   V√©rit√© terrain: {vraie_valeur} {correct}")
        
        print("-" * 80)

def diagnostic_modele(model, feature_cols):
    """diagnostic approfondi du comportement du mod√®le"""
    print("\n" + "=" * 80)
    print("DIAGNOSTIC DU MOD√àLE")
    print("=" * 80)
    
    # charger quelques vrais √©chantillons accessibles du dataset
    print("chargement d'√©chantillons r√©els accessibles...")
    df_train = pd.read_csv('../2-TravailPreparationdesDonn√©es/data_prepared_EXPLORATION.csv')
    
    # prendre des √©chantillons r√©els accessibles
    vrais_accessibles = df_train[df_train['entree_pmr'] == True].head(3)
    
    print(f"trouv√© {len(vrais_accessibles)} √©chantillons r√©els accessibles")
    
    # afficher leurs caract√©ristiques
    total_tests = 0
    tests_reussis = 0
    
    for i, (idx, row) in enumerate(vrais_accessibles.iterrows()):
        total_tests += 1
        
        print(f"\nüìä √âCHANTILLON R√âEL ACCESSIBLE {i+1}:")
        print(f"   Nom: {row.get('name', 'N/A')}")
        print(f"   Activit√©: {row.get('activite', 'N/A')}")
        print(f"   Largeur entr√©e: {row.get('entree_largeur_mini', 'N/A')} cm")
        print(f"   Marches: {row.get('entree_marches', 'N/A')}")
        print(f"   Sanitaires: {row.get('sanitaires_presence', 'N/A')}")
        print(f"   Stationnement PMR: {row.get('stationnement_pmr', 'N/A')}")
        print(f"   Transport: {row.get('transport_station_presence', 'N/A')}")
        
        # pr√©parer pour pr√©diction
        test_row = row[feature_cols].copy()
        
        # encoder les variables cat√©gorielles
        from sklearn.preprocessing import LabelEncoder
        for col in test_row.index:
            if df_train[col].dtype == 'object':
                le = LabelEncoder()
                le.fit(df_train[col].astype(str))
                test_row[col] = le.transform([str(test_row[col])])[0]
        
        # g√©rer les valeurs manquantes
        test_row = test_row.fillna(0)
        
        # pr√©diction avec seuil optimis√©
        prob = model.predict_proba([test_row])[0]
        
        # appliquer le seuil optimal de 0.35
        optimal_threshold = 0.35
        pred = 1 if prob[1] >= optimal_threshold else 0
        
        result = "ACCESSIBLE" if pred == 1 else "NON ACCESSIBLE"
        prob_accessible = prob[1]
        
        # v√©rifier si c'est correct
        is_correct = (pred == 1)  # car on teste des √©chantillons accessibles
        if is_correct:
            tests_reussis += 1
            status = "‚úÖ CORRECT"
        else:
            status = "‚ùå INCORRECT"
        
        print(f"\nüéØ PR√âDICTION SUR CET √âCHANTILLON R√âEL:")
        print(f"   R√©sultat: {result}")
        print(f"   Confiance: {prob_accessible*100:.1f}%")
        print(f"   Probabilit√©s: Non={prob[0]:.3f}, Oui={prob[1]:.3f}")
        print(f"   V√©rit√©: ACCESSIBLE {status}")
        print("-" * 60)
    
    # afficher le taux de r√©ussite global
    taux_reussite = (tests_reussis / total_tests) * 100 if total_tests > 0 else 0
    
    print(f"\nüéØ TAUX DE R√âUSSITE SUR √âCHANTILLONS R√âELS ACCESSIBLES:")
    print(f"   Tests r√©ussis: {tests_reussis}/{total_tests}")
    print(f"   Taux de r√©ussite: {taux_reussite:.1f}%")
    
    if taux_reussite >= 70:
        print(f"   √âvaluation: ‚úÖ EXCELLENT (‚â•70%)")
    elif taux_reussite >= 50:
        print(f"   √âvaluation: ‚ö†Ô∏è CORRECT (‚â•50%)")
    else:
        print(f"   √âvaluation: ‚ùå INSUFFISANT (<50%)")

    # test avec un √©chantillon "parfait"
    print(f"\nüß™ TEST AVEC √âCHANTILLON 'PARFAIT':")
    
    # cr√©er un √©chantillon avec toutes les meilleures valeurs
    perfect_sample = {}
    for col in feature_cols:
        if col == 'activite':
            # utiliser la valeur la plus fr√©quente chez les accessibles
            activites_accessibles = df_train[df_train['entree_pmr'] == True]['activite'].value_counts()
            if len(activites_accessibles) > 0:
                perfect_sample[col] = activites_accessibles.index[0]
            else:
                perfect_sample[col] = 'Commerce'
        elif col == 'entree_largeur_mini':
            perfect_sample[col] = 150  # tr√®s large
        elif col == 'entree_marches':
            perfect_sample[col] = 0    # pas de marches
        elif col in ['sanitaires_presence', 'stationnement_pmr', 'transport_station_presence', 
                     'cheminement_ext_presence', 'entree_plain_pied', 'stationnement_ext_pmr']:
            perfect_sample[col] = 1    # tout pr√©sent
        else:
            # valeur par d√©faut
            perfect_sample[col] = 1
    
    print(f"   Activit√©: {perfect_sample['activite']}")
    print(f"   Largeur: {perfect_sample['entree_largeur_mini']} cm")
    print(f"   Marches: {perfect_sample['entree_marches']}")
    print(f"   Sanitaires: {perfect_sample['sanitaires_presence']}")
    print(f"   Stationnement: {perfect_sample['stationnement_pmr']}")
    
    # encoder et pr√©dire avec seuil optimis√©
    test_perfect = pd.Series(perfect_sample)
    for col in test_perfect.index:
        if df_train[col].dtype == 'object':
            le = LabelEncoder()
            le.fit(df_train[col].astype(str))
            try:
                test_perfect[col] = le.transform([str(test_perfect[col])])[0]
            except:
                test_perfect[col] = 0  # valeur par d√©faut si inconnue
    
    # pr√©diction avec seuil optimis√©
    prob_perfect = model.predict_proba([test_perfect])[0]
    
    # appliquer le seuil optimal de 0.2
    optimal_threshold = 0.35
    pred_perfect = 1 if prob_perfect[1] >= optimal_threshold else 0
    
    result_perfect = "ACCESSIBLE" if pred_perfect == 1 else "NON ACCESSIBLE"
    prob_accessible_perfect = prob_perfect[1]
    
    print(f"\n PR√âDICTION SUR L'√âCHANTILLON PARFAIT (seuil {optimal_threshold}):")
    print(f"   R√©sultat: {result_perfect}")
    print(f"   Probabilit√© accessible: {prob_accessible_perfect:.3f}")
    print(f"   Seuil standard (0.5): {'ACCESSIBLE' if prob_accessible_perfect >= 0.5 else 'NON ACCESSIBLE'}")
    print(f"   Seuil optimis√© ({optimal_threshold}): {result_perfect}")
    
    # analyser les importances des features
    if hasattr(model, 'feature_importances_'):
        print(f"\n TOP 10 VARIABLES LES PLUS IMPORTANTES:")
        importances = model.feature_importances_
        feature_importance = list(zip(feature_cols, importances))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        for i, (feature, importance) in enumerate(feature_importance[:10]):
            print(f"   {i+1:2d}. {feature}: {importance:.3f} ({importance*100:.1f}%)")
    
    

def create_custom_test(model, feature_cols):
    """cr√©e un test avec des valeurs personnalis√©es"""
    print("\n" + "=" * 80)
    print("TEST AVEC √âTABLISSEMENTS PERSONNALIS√âS")
    print("=" * 80)
    
    # charger le dataset pour l'encodage
    df_train = pd.read_csv('../2-TravailPreparationdesDonn√©es/data_prepared_EXPLORATION.csv')
    
    # exemple d'√©tablissement accessible
    etablissement_accessible = {
        'entree_largeur_mini': 120,     
        'entree_marches': 0,             
        'sanitaires_presence': 1,        
        'stationnement_pmr': 1,          
        'activite': 'Commerce',          
        'transport_station_presence': 1   
    }
    
    # exemple d'√©tablissement non accessible
    etablissement_non_accessible = {
        'entree_largeur_mini': 60,       
        'entree_marches': 5,             
        'sanitaires_presence': 0,        
        'stationnement_pmr': 0,          
        'activite': 'Restaurant',        
        'transport_station_presence': 0   
    }
    
    etablissements = [
        ('ACCESSIBLE', etablissement_accessible),
        ('NON ACCESSIBLE', etablissement_non_accessible)
    ]
    
    for attendu, etab in etablissements:
        print(f"\n √âTABLISSEMENT TH√âORIQUEMENT {attendu}:")
        print(f"   Largeur entr√©e: {etab['entree_largeur_mini']} cm")
        print(f"   Nombre de marches: {etab['entree_marches']}")
        print(f"   Sanitaires pr√©sents: {'Oui' if etab['sanitaires_presence'] else 'Non'}")
        print(f"   Stationnement PMR: {'Oui' if etab['stationnement_pmr'] else 'Non'}")
        print(f"   Activit√©: {etab['activite']}")
        print(f"   Transport accessible: {'Oui' if etab['transport_station_presence'] else 'Non'}")
        
        # pr√©parer les donn√©es pour le mod√®le
        test_data = {}
        for col in feature_cols:
            if col in etab:
                test_data[col] = etab[col]
            else:
                # valeurs par d√©faut pour les colonnes manquantes
                if col in ['entree_marches_main_courante', 'entree_marches_rampe', 'entree_marches_reperage', 'entree_marches_sens']:
                    test_data[col] = 0
                elif col in ['accueil_retrecissement', 'accueil_visibilite', 'accueil_cheminement_plain_pied']:
                    test_data[col] = 1
                elif col in ['entree_porte_manoeuvre', 'entree_porte_type', 'entree_porte_presence']:
                    test_data[col] = 1
                elif col in ['entree_ascenseur']:
                    test_data[col] = 0
                elif col in ['stationnement_presence', 'stationnement_ext_presence']:
                    test_data[col] = 1
                else:
                    test_data[col] = 0
        
        # convertir en Series et encoder
        test_series = pd.Series(test_data)
        
        # encoder les variables cat√©gorielles
        from sklearn.preprocessing import LabelEncoder
        for col in test_series.index:
            if df_train[col].dtype == 'object':
                le = LabelEncoder()
                le.fit(df_train[col].astype(str))
                try:
                    test_series[col] = le.transform([str(test_series[col])])[0]
                except:
                    test_series[col] = 0  # valeur par d√©faut si inconnue
        
        # faire la pr√©diction avec seuil optimis√©
        prob = model.predict_proba([test_series])[0]
        
        # appliquer le seuil optimal de 0.2
        optimal_threshold = 0.35
        pred = 1 if prob[1] >= optimal_threshold else 0
        
        result = "ACCESSIBLE" if pred == 1 else "NON ACCESSIBLE"
        prob_accessible = prob[1]
        correct = "‚úÖ CORRECT" if result == attendu else "‚ùå INCORRECT"
        
        print(f"\n PR√âDICTION DU MOD√àLE (seuil {optimal_threshold}):")
        print(f"   R√©sultat: {result}")
        print(f"   Probabilit√© accessible: {prob_accessible:.3f}")
        print(f"   Seuil standard (0.5): {'ACCESSIBLE' if prob_accessible >= 0.5 else 'NON ACCESSIBLE'}")
        print(f"   Seuil optimis√© ({optimal_threshold}): {result}")
        print(f"   Attendu: {attendu} {correct}")
        

def main():
    """fonction principale de test du mod√®le"""
    
    print("TEST DU MOD√àLE ML - ACCESSIBILIT√â PMR")
    
    
    # charger le mod√®le
    model, df, feature_names = load_model_and_data()
    if model is None:
        return
    
    # pr√©parer les √©chantillons de test
    test_samples, _, sample_original = prepare_test_sample_simple(df, feature_names)
    
    if test_samples is None:
        print("erreur lors de la pr√©paration des √©chantillons de test")
        return
    
    # tester le mod√®le
    test_model_predictions(model, test_samples, sample_original)
    
    # diagnostic du mod√®le
    diagnostic_modele(model, feature_names)
    
    # exemple personnalis√©
    create_custom_test(model, feature_names)
    
    print("TEST TERMIN√â")

if __name__ == "__main__":
    main()
